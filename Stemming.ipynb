{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebda406b",
   "metadata": {},
   "source": [
    "# Stemming.\n",
    "\n",
    "        Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes to the root of the words known as lemma.Stemming is important in Natural Language Understanding(NLU) and Natural Language process(NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ca5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Stemmer library\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba94be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f775cb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('driving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ebf0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['going','asking','playing','drinking','laughing','eating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54bd1300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going\n",
      "asking\n",
      "playing\n",
      "drinking\n",
      "laughing\n",
      "eating\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7c1857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going------>go\n",
      "asking------>ask\n",
      "playing------>play\n",
      "drinking------>drink\n",
      "laughing------>laugh\n",
      "eating------>eat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'------>'+stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "342e472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"In this course you will learn what Artificial Intelligence (AI) is, explore use cases and applications of AI, \n",
    "understand AI concepts and terms like machine learning, deep learning and neural networks. You will be exposed to various \n",
    "issues and concerns surrounding AI such as ethics and bias, & jobs, and get advice from experts about learning and starting \n",
    "a career in AI.  You will also demonstrate AI in action with a mini project.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7faf793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d631a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26fbfea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'this',\n",
       " 'course',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'what',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " '(',\n",
       " 'AI',\n",
       " ')',\n",
       " 'is',\n",
       " ',',\n",
       " 'explore',\n",
       " 'use',\n",
       " 'cases',\n",
       " 'and',\n",
       " 'applications',\n",
       " 'of',\n",
       " 'AI',\n",
       " ',',\n",
       " 'understand',\n",
       " 'AI',\n",
       " 'concepts',\n",
       " 'and',\n",
       " 'terms',\n",
       " 'like',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'neural',\n",
       " 'networks',\n",
       " '.',\n",
       " 'You',\n",
       " 'will',\n",
       " 'be',\n",
       " 'exposed',\n",
       " 'to',\n",
       " 'various',\n",
       " 'issues',\n",
       " 'and',\n",
       " 'concerns',\n",
       " 'surrounding',\n",
       " 'AI',\n",
       " 'such',\n",
       " 'as',\n",
       " 'ethics',\n",
       " 'and',\n",
       " 'bias',\n",
       " ',',\n",
       " '&',\n",
       " 'jobs',\n",
       " ',',\n",
       " 'and',\n",
       " 'get',\n",
       " 'advice',\n",
       " 'from',\n",
       " 'experts',\n",
       " 'about',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'starting',\n",
       " 'a',\n",
       " 'career',\n",
       " 'in',\n",
       " 'AI',\n",
       " '.',\n",
       " 'You',\n",
       " 'will',\n",
       " 'also',\n",
       " 'demonstrate',\n",
       " 'AI',\n",
       " 'in',\n",
       " 'action',\n",
       " 'with',\n",
       " 'a',\n",
       " 'mini',\n",
       " 'project',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "749d54ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In--->in\n",
      "this--->thi\n",
      "course--->cours\n",
      "you--->you\n",
      "will--->will\n",
      "learn--->learn\n",
      "what--->what\n",
      "Artificial--->artifici\n",
      "Intelligence--->intellig\n",
      "(--->(\n",
      "AI--->ai\n",
      ")--->)\n",
      "is--->is\n",
      ",--->,\n",
      "explore--->explor\n",
      "use--->use\n",
      "cases--->case\n",
      "and--->and\n",
      "applications--->applic\n",
      "of--->of\n",
      "AI--->ai\n",
      ",--->,\n",
      "understand--->understand\n",
      "AI--->ai\n",
      "concepts--->concept\n",
      "and--->and\n",
      "terms--->term\n",
      "like--->like\n",
      "machine--->machin\n",
      "learning--->learn\n",
      ",--->,\n",
      "deep--->deep\n",
      "learning--->learn\n",
      "and--->and\n",
      "neural--->neural\n",
      "networks--->network\n",
      ".--->.\n",
      "You--->you\n",
      "will--->will\n",
      "be--->be\n",
      "exposed--->expos\n",
      "to--->to\n",
      "various--->variou\n",
      "issues--->issu\n",
      "and--->and\n",
      "concerns--->concern\n",
      "surrounding--->surround\n",
      "AI--->ai\n",
      "such--->such\n",
      "as--->as\n",
      "ethics--->ethic\n",
      "and--->and\n",
      "bias--->bia\n",
      ",--->,\n",
      "&--->&\n",
      "jobs--->job\n",
      ",--->,\n",
      "and--->and\n",
      "get--->get\n",
      "advice--->advic\n",
      "from--->from\n",
      "experts--->expert\n",
      "about--->about\n",
      "learning--->learn\n",
      "and--->and\n",
      "starting--->start\n",
      "a--->a\n",
      "career--->career\n",
      "in--->in\n",
      "AI--->ai\n",
      ".--->.\n",
      "You--->you\n",
      "will--->will\n",
      "also--->also\n",
      "demonstrate--->demonstr\n",
      "AI--->ai\n",
      "in--->in\n",
      "action--->action\n",
      "with--->with\n",
      "a--->a\n",
      "mini--->mini\n",
      "project--->project\n",
      ".--->.\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'--->'+stemmer.stem(word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
